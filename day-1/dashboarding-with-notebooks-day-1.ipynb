{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook was forked from the original by Rachael Tatman at Kaggle, which was provided as part of the Kaggle Professional Skills series on Dashboarding with Notebooks. This is the first in a series of 5 notebooks, with one for each day of the course.\n",
    "\n",
    "The first cell gives information and instructions to outline the requirements; the subsequent cells detail the steps to completion.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52dbbac77891f1f2046a350600f0bdce027c66c7"
   },
   "source": [
    "Welcome to the first day of Dashboarding with scheduled notebooks. Today we're going to do two things:\n",
    "\n",
    "* Pick a dataset to work with\n",
    "* Figure out what data we should include in our dashboard\n",
    "\n",
    "Today's timeline: \n",
    "\n",
    "* **5 minutes:** Read notebook\n",
    "* **5 minutes:** Pick dataset and read over the documentation, determining what the most important information should be\n",
    "* **5 minutes:** Start kernel and read in data\n",
    "* **5 minutes:** Create one or more visualizations (no need to worry about pretty; quick and dirty will work!)\n",
    "\n",
    "# Picking a dataset\n",
    "\n",
    "Not every dataset needs to be dashboarded. Dashboards are useful because they make it easy to monitor things that change over time, which means it only makes sense to use datasets that are updated; there's usually no reason to go to all the trouble of building a dashboard for a static dataset when a plain notebook or markdown document will do just as well. \n",
    "\n",
    "The method we're going to be using--scheduling our notebooks rather than continuously updating them--works best for datasets that are batch processed. \n",
    "\n",
    "> **Batch data processing** refers to data processing that happens at a single point in time, usually by running a script. It's opposed to **streaming data processing** which happens continuously. \n",
    "\n",
    "I've put together a list of Kaggle datasets that are batch processed and updated daily for you here. It’s mostly public data that’s provided by cities in the US, but Kaggle’s own public data, Meta Kaggle, is also updated daily. Pick one that you like and create a new Kernel using it as a data source. \n",
    "\n",
    "* [Meta Kaggle](https://www.kaggle.com/kaggle/meta-kaggle)\n",
    "* [Procurement Notices](https://www.kaggle.com/theworldbank/procurement-notices)\n",
    "* [Chicago Red Light and Speed Camera Data](https://www.kaggle.com/chicago/chicago-red-light-and-speed-camera-data)\n",
    "* [Chicago 311 Service Requests](https://www.kaggle.com/chicago/chicago-311-service-requests)\n",
    "* [Seattle Road Weather Information Stations](https://www.kaggle.com/city-of-seattle/seattle-road-weather-information-stations)\n",
    "* [Seattle Use of Force](https://www.kaggle.com/city-of-seattle/seattle-use-of-force) (There's currently a problem with our mirror of this dataset. You can also access the data [here](https://www.seattle.gov/police/information-and-data/use-of-force-data).)\n",
    "* [Seattle Crisis Data](https://www.kaggle.com/city-of-seattle/seattle-crisis-data)\n",
    "* [Los Angeles Parking Citations](https://www.kaggle.com/cityofLA/los-angeles-parking-citations)\n",
    "* [What's Happening LA Calendar Dataset](https://www.kaggle.com/cityofLA/what's-happening-la-calendar-dataset)\n",
    "* [Oakland Call Center & Public Work Service Requests](https://www.kaggle.com/cityofoakland/oakland-call-center-public-work-service-requests)\n",
    "* [NY Bus Breakdown and Delays](https://www.kaggle.com/new-york-city/ny-bus-breakdown-and-delays)\n",
    "* [NYPD Motor Vehicle Collisions](https://www.kaggle.com/new-york-city/nypd-motor-vehicle-collisions)\n",
    "* [NY Daily Inmates In Custody](https://www.kaggle.com/new-york-city/ny-daily-inmates-in-custody)\n",
    "* [NYS Turnstile Usage Data](https://www.kaggle.com/new-york-state/nys-turnstile-usage-data)\n",
    "* [NOAA Global Surface Summary of the Day](https://www.kaggle.com/noaa/noaa-global-surface-summary-of-the-day/)\n",
    "* [SF Fire Data (Incidents, Violations, and more)](https://www.kaggle.com/san-francisco/sf-fire-data-incidents-violations-and-more)\n",
    "* [SF Restaurant Scores - LIVES Standard](https://www.kaggle.com/san-francisco/sf-restaurant-scores-lives-standard)\n",
    "\n",
    "# Figure out what data should be dashboarded\n",
    "\n",
    "Because we're picking public datasets rather than working from one we've been given by our co-workers, we unfortunately can't use the most effective technique to figure out what information to include: asking whoever gave you the data. \n",
    "\n",
    "> The easiest way to figure out what to include in a dashboard is to ask stakeholders (other people that care about what's in your data and you would want to use the dashboard) what they'd consider the most important information.\n",
    "\n",
    "Failing that, there are some general guidelines you can use to figure out what information to include in a dashboard. \n",
    "\n",
    "* *What information is changing relatively quickly (every day or hour)?* Information that only changes every quarter or year probably belong in a report, not a dashboard. \n",
    "* *What information is the most important to your mission?* If you're a company, things like money or users are probably going to be pretty important, but if you're a school district you probably care more about things like attendance or grades.\n",
    "* *What will affect the choices you or others will need to make?* Are you running A/B tests and need to choose which model to keep in production based on them? Then it's probably important that you track your metrics and other things that might affect those metrics, like sales that are running at the same time. Is there some outside factor that might affect your business, like the weather forecast next week? Then it might make sense to pull in another dataset and show that as well.\n",
    "* *What changes have you made?* If you're tuning parameters or adjusting teaching schedules, you want to track the fact that you've made those changes and also how they've affected outcomes.\n",
    "\n",
    "# Your turn!\n",
    "\n",
    "Pick a dataset that's updated daily by Kaggle from this list. Imagine you work for the organization that produced it and identify factors in the dataset that might represent:\n",
    "\n",
    "* The goals of your organization (like users or measures of pollution)\n",
    "* Things that you (or your colleagues) can change to affect those goals (like advertising spending or the number of factory inspections)\n",
    "* Thing you can't change but that will affect the outcome (like the school year, or weather conditions)\n",
    "\n",
    "You might not find all three in the same dataset, but you should be able to pinpoint at least one. I'd recommend using the summary statistics in the Data tab of the dataset or reading the documentation in the Overview tab to help identify them.\n",
    "\n",
    "Then start a kernel on that dataset ([this video has a quick walk-through if you need a quick refresher on how to do this](https://youtu.be/fvF2H85ko9c)) and put together two quick visualizations or summary tables that show two of the factors you've identified in the first step.\n",
    "\n",
    "If you like, you can make your kernel public and share a link to it in the comments on this dataset to share with other participants. (And you can take a peek at other people's work to see what they've chosen to look at!) I'll pick a couple that I especially like to highlight as examples. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # Easy-to-use, cross-platform path-to-file.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset selection\n",
    "I chose to work with the [NYS Turnstile Usage Data](https://www.kaggle.com/new-york-state/nys-turnstile-usage-data) as a find pedestrian behaviour and human flow dynamics quite interesting. Data is provided for 2017 and 2018 and contains the following fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "| **Data Label**  | **Data Type**  | **Description**  | **Example Values** |\n",
    "| --- | --- | --- | --- |\n",
    "| C/A | String | Internal identification of a booth at a given station | A002 |\n",
    "| UnitRemote | String | Unit ID of station | R001 |\n",
    "| SCP | String | Address for a given device | 01-00-01 |\n",
    "| StationName | String | Used in all references to station | 34 ST-HERALD SQ |\n",
    "| Line Name | String | Train lines stopping at this location | 456 |\n",
    "| Division | String | Operating company the line originally belong to | BMT |\n",
    "| Date | Date | Date of the audit data (MM/DD/YYYY) | 11/18/2017 |\n",
    "| Time | Time | Time of the reported data (HH:MM:SS) | 02:00:00 |\n",
    "| Description | String | Represents the \"REGULAR\" scheduled audit event (Normally occurs every 4 hours) | REGULAR |\n",
    "| Entries | Integer | Cumulative ENTRY register value for a device; initialized during system setup | 0001649720 |\n",
    "| Exits | Integer | Cumulative EXITS register value for a device. Similar to Entries | 0004863606 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional information: \n",
    "- Data is transmitted in the form of audit reports. The normal interval between audit reports for the same device is 4 hours. The four hour intervals will differ from other stations due to the need for staggering to prevent flooding the system with audit readings all at once. System-wide, stations have been set to begin audit transmittal between 00 to 03 hours, then every 4 hours after the first audit of the day\n",
    "- Audits may occur more frequently than 4 hours due to planning, or troubleshooting activities. Furthermore, there may be a \"RECOVR AUD\" entry, refering to a missed audit that was recovered\n",
    "\n",
    "The essense of this data is that it provides a number (entries/exits), per time, per location (booth/station); other fields provide information that can be used to gain deeper insight (e.g. Line Name) or that is used by the operator for control/monitoring of the system (e.g. audit event description)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = Path('nys-turnstile-usage-data')\n",
    "\n",
    "datafiles = ['turnstile-usage-data-2017.csv', 'turnstile-usage-data-2018.csv']\n",
    "data = [pd.read_csv(path_to_data / filename) for filename in datafiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>Unit</th>\n",
       "      <th>SCP</th>\n",
       "      <th>Station</th>\n",
       "      <th>Line Name</th>\n",
       "      <th>Division</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Description</th>\n",
       "      <th>Entries</th>\n",
       "      <th>Exits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016-12-31T00:00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5991546</td>\n",
       "      <td>2028378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016-12-31T00:00:00</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5991565</td>\n",
       "      <td>2028389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016-12-31T00:00:00</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5991644</td>\n",
       "      <td>2028441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016-12-31T00:00:00</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5991971</td>\n",
       "      <td>2028502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2016-12-31T00:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5992418</td>\n",
       "      <td>2028543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  Unit       SCP Station Line Name Division                 Date  \\\n",
       "0  A002  R051  02-00-00   59 ST   NQR456W      BMT  2016-12-31T00:00:00   \n",
       "1  A002  R051  02-00-00   59 ST   NQR456W      BMT  2016-12-31T00:00:00   \n",
       "2  A002  R051  02-00-00   59 ST   NQR456W      BMT  2016-12-31T00:00:00   \n",
       "3  A002  R051  02-00-00   59 ST   NQR456W      BMT  2016-12-31T00:00:00   \n",
       "4  A002  R051  02-00-00   59 ST   NQR456W      BMT  2016-12-31T00:00:00   \n",
       "\n",
       "       Time Description  Entries  \\\n",
       "0  03:00:00     REGULAR  5991546   \n",
       "1  07:00:00     REGULAR  5991565   \n",
       "2  11:00:00     REGULAR  5991644   \n",
       "3  15:00:00     REGULAR  5991971   \n",
       "4  19:00:00     REGULAR  5992418   \n",
       "\n",
       "   Exits                                                       \n",
       "0                                            2028378           \n",
       "1                                            2028389           \n",
       "2                                            2028441           \n",
       "3                                            2028502           \n",
       "4                                            2028543           "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
